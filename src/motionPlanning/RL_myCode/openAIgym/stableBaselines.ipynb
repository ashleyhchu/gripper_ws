{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install tensorflow==1.14.0 tensorflow-gpu==1.14.0 --user\n",
    "# !pip install stable_baselines gym box2d-py --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ash/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ash/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ash/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ash/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ash/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ash/.local/lib/python3.6/site-packages/stable_baselines/__init__.py:33: UserWarning: stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\n",
      "  \"stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\"\n"
     ]
    }
   ],
   "source": [
    "import gym \n",
    "from stable_baselines import ACER\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = 'LunarLander-v2'\n",
    "# environment_name = 'LunarLanderContinuous-v2'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Test Random Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(environment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-108.13662596729576\n",
      "Episode:2 Score:-111.6733148695925\n",
      "Episode:3 Score:-105.21778784049809\n",
      "Episode:4 Score:-170.43017170913492\n",
      "Episode:5 Score:-238.5776981760699\n",
      "Episode:6 Score:-291.57957537232454\n",
      "Episode:7 Score:-270.13437432072374\n",
      "Episode:8 Score:-165.02181701674527\n",
      "Episode:9 Score:-119.77795063063887\n",
      "Episode:10 Score:-299.58580688014274\n"
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ash/.local/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ash/.local/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ash/.local/lib/python3.6/site-packages/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ash/.local/lib/python3.6/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ash/.local/lib/python3.6/site-packages/stable_baselines/common/policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/ash/.local/lib/python3.6/site-packages/stable_baselines/common/tf_layers.py:123: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ash/.local/lib/python3.6/site-packages/tensorflow/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /home/ash/.local/lib/python3.6/site-packages/stable_baselines/acer/acer_simple.py:421: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ash/.local/lib/python3.6/site-packages/tensorflow/python/ops/clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/ash/.local/lib/python3.6/site-packages/stable_baselines/acer/acer_simple.py:479: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ash/.local/lib/python3.6/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/ash/.local/lib/python3.6/site-packages/stable_baselines/acer/acer_simple.py:506: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(environment_name)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "model = ACER('MlpPolicy', env, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| avg_norm_adj        | 7.21      |\n",
      "| avg_norm_g          | 29.9      |\n",
      "| avg_norm_grads_f    | 25.9      |\n",
      "| avg_norm_k          | 2         |\n",
      "| avg_norm_k_dot_g    | 29.9      |\n",
      "| entropy             | 29.1      |\n",
      "| explained_variance  | -9.47e-05 |\n",
      "| fps                 | 0         |\n",
      "| loss                | 4.36      |\n",
      "| loss_bc             | -0        |\n",
      "| loss_f              | -10.3     |\n",
      "| loss_policy         | -10.3     |\n",
      "| loss_q              | 30        |\n",
      "| mean_episode_length | 0         |\n",
      "| mean_episode_reward | 0         |\n",
      "| norm_grads          | 7.3       |\n",
      "| norm_grads_policy   | 4.52      |\n",
      "| norm_grads_q        | 5.73      |\n",
      "| total_timesteps     | 20        |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 7.98     |\n",
      "| avg_norm_g          | 32.3     |\n",
      "| avg_norm_grads_f    | 27.7     |\n",
      "| avg_norm_k          | 2.02     |\n",
      "| avg_norm_k_dot_g    | 33.7     |\n",
      "| entropy             | 28.9     |\n",
      "| explained_variance  | 0.0256   |\n",
      "| fps                 | 1079     |\n",
      "| loss                | 6.82     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -10.8    |\n",
      "| loss_policy         | -10.8    |\n",
      "| loss_q              | 35.8     |\n",
      "| mean_episode_length | 96       |\n",
      "| mean_episode_reward | -183     |\n",
      "| norm_grads          | 11.5     |\n",
      "| norm_grads_policy   | 5.66     |\n",
      "| norm_grads_q        | 10.1     |\n",
      "| total_timesteps     | 2020     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 17.4     |\n",
      "| avg_norm_g          | 76.4     |\n",
      "| avg_norm_grads_f    | 66.6     |\n",
      "| avg_norm_k          | 2.13     |\n",
      "| avg_norm_k_dot_g    | 79.1     |\n",
      "| entropy             | 24.3     |\n",
      "| explained_variance  | -0.025   |\n",
      "| fps                 | 1058     |\n",
      "| loss                | 79.1     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -22.7    |\n",
      "| loss_policy         | -22.7    |\n",
      "| loss_q              | 204      |\n",
      "| mean_episode_length | 103      |\n",
      "| mean_episode_reward | -162     |\n",
      "| norm_grads          | 44       |\n",
      "| norm_grads_policy   | 9.67     |\n",
      "| norm_grads_q        | 42.9     |\n",
      "| total_timesteps     | 4020     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 5.35     |\n",
      "| avg_norm_g          | 25.8     |\n",
      "| avg_norm_grads_f    | 22.8     |\n",
      "| avg_norm_k          | 2.21     |\n",
      "| avg_norm_k_dot_g    | 26       |\n",
      "| entropy             | 19.7     |\n",
      "| explained_variance  | 0.0994   |\n",
      "| fps                 | 1015     |\n",
      "| loss                | 15.7     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -6.34    |\n",
      "| loss_policy         | -6.34    |\n",
      "| loss_q              | 44.5     |\n",
      "| mean_episode_length | 138      |\n",
      "| mean_episode_reward | -161     |\n",
      "| norm_grads          | 30.1     |\n",
      "| norm_grads_policy   | 6.28     |\n",
      "| norm_grads_q        | 29.4     |\n",
      "| total_timesteps     | 6020     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 6.11     |\n",
      "| avg_norm_g          | 23.7     |\n",
      "| avg_norm_grads_f    | 20.3     |\n",
      "| avg_norm_k          | 1.95     |\n",
      "| avg_norm_k_dot_g    | 23.7     |\n",
      "| entropy             | 11.1     |\n",
      "| explained_variance  | 0.0164   |\n",
      "| fps                 | 958      |\n",
      "| loss                | 86.9     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -3.91    |\n",
      "| loss_policy         | -3.91    |\n",
      "| loss_q              | 182      |\n",
      "| mean_episode_length | 173      |\n",
      "| mean_episode_reward | -152     |\n",
      "| norm_grads          | 65.5     |\n",
      "| norm_grads_policy   | 7.14     |\n",
      "| norm_grads_q        | 65.1     |\n",
      "| total_timesteps     | 8020     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 10.2     |\n",
      "| avg_norm_g          | 43.5     |\n",
      "| avg_norm_grads_f    | 37.8     |\n",
      "| avg_norm_k          | 1.99     |\n",
      "| avg_norm_k_dot_g    | 44       |\n",
      "| entropy             | 25.6     |\n",
      "| explained_variance  | 0.178    |\n",
      "| fps                 | 927      |\n",
      "| loss                | 26.5     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -13.7    |\n",
      "| loss_policy         | -13.7    |\n",
      "| loss_q              | 81       |\n",
      "| mean_episode_length | 194      |\n",
      "| mean_episode_reward | -141     |\n",
      "| norm_grads          | 35.6     |\n",
      "| norm_grads_policy   | 18.9     |\n",
      "| norm_grads_q        | 30.2     |\n",
      "| total_timesteps     | 10020    |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| avg_norm_adj        | 15.2      |\n",
      "| avg_norm_g          | 74.2      |\n",
      "| avg_norm_grads_f    | 66.6      |\n",
      "| avg_norm_k          | 2.24      |\n",
      "| avg_norm_k_dot_g    | 72        |\n",
      "| entropy             | 9.31      |\n",
      "| explained_variance  | -0.000272 |\n",
      "| fps                 | 924       |\n",
      "| loss                | 41.1      |\n",
      "| loss_bc             | -0        |\n",
      "| loss_f              | -5.75     |\n",
      "| loss_policy         | -5.75     |\n",
      "| loss_q              | 93.8      |\n",
      "| mean_episode_length | 239       |\n",
      "| mean_episode_reward | -137      |\n",
      "| norm_grads          | 19.1      |\n",
      "| norm_grads_policy   | 16.6      |\n",
      "| norm_grads_q        | 9.45      |\n",
      "| total_timesteps     | 12020     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 11       |\n",
      "| avg_norm_g          | 41.2     |\n",
      "| avg_norm_grads_f    | 35       |\n",
      "| avg_norm_k          | 1.99     |\n",
      "| avg_norm_k_dot_g    | 42.2     |\n",
      "| entropy             | 13.3     |\n",
      "| explained_variance  | 0.00737  |\n",
      "| fps                 | 894      |\n",
      "| loss                | 18.1     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -6.95    |\n",
      "| loss_policy         | -6.95    |\n",
      "| loss_q              | 50.4     |\n",
      "| mean_episode_length | 281      |\n",
      "| mean_episode_reward | -122     |\n",
      "| norm_grads          | 26.3     |\n",
      "| norm_grads_policy   | 5.38     |\n",
      "| norm_grads_q        | 25.8     |\n",
      "| total_timesteps     | 14020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.159    |\n",
      "| avg_norm_g          | 29       |\n",
      "| avg_norm_grads_f    | 28.9     |\n",
      "| avg_norm_k          | 2.09     |\n",
      "| avg_norm_k_dot_g    | 27.4     |\n",
      "| entropy             | 13.8     |\n",
      "| explained_variance  | 0.0129   |\n",
      "| fps                 | 906      |\n",
      "| loss                | 103      |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 8.47     |\n",
      "| loss_policy         | 8.47     |\n",
      "| loss_q              | 189      |\n",
      "| mean_episode_length | 302      |\n",
      "| mean_episode_reward | -109     |\n",
      "| norm_grads          | 68.6     |\n",
      "| norm_grads_policy   | 37.2     |\n",
      "| norm_grads_q        | 57.7     |\n",
      "| total_timesteps     | 16020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.053    |\n",
      "| avg_norm_g          | 6.56     |\n",
      "| avg_norm_grads_f    | 6.51     |\n",
      "| avg_norm_k          | 1.95     |\n",
      "| avg_norm_k_dot_g    | 4.04     |\n",
      "| entropy             | 21.1     |\n",
      "| explained_variance  | 0.452    |\n",
      "| fps                 | 891      |\n",
      "| loss                | 1.27     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 1.25     |\n",
      "| loss_policy         | 1.25     |\n",
      "| loss_q              | 0.451    |\n",
      "| mean_episode_length | 299      |\n",
      "| mean_episode_reward | -95.3    |\n",
      "| norm_grads          | 6.64     |\n",
      "| norm_grads_policy   | 6.19     |\n",
      "| norm_grads_q        | 2.4      |\n",
      "| total_timesteps     | 18020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.0723   |\n",
      "| avg_norm_g          | 1.27     |\n",
      "| avg_norm_grads_f    | 1.22     |\n",
      "| avg_norm_k          | 2.52     |\n",
      "| avg_norm_k_dot_g    | 1.21     |\n",
      "| entropy             | 19.2     |\n",
      "| explained_variance  | 0.0124   |\n",
      "| fps                 | 874      |\n",
      "| loss                | -0.416   |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.39    |\n",
      "| loss_policy         | -0.39    |\n",
      "| loss_q              | 0.333    |\n",
      "| mean_episode_length | 325      |\n",
      "| mean_episode_reward | -96      |\n",
      "| norm_grads          | 6.22     |\n",
      "| norm_grads_policy   | 1.53     |\n",
      "| norm_grads_q        | 6.03     |\n",
      "| total_timesteps     | 20020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 131      |\n",
      "| avg_norm_grads_f    | 131      |\n",
      "| avg_norm_k          | 2.28     |\n",
      "| avg_norm_k_dot_g    | 145      |\n",
      "| entropy             | 16.2     |\n",
      "| explained_variance  | 0.0644   |\n",
      "| fps                 | 839      |\n",
      "| loss                | 472      |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 28.5     |\n",
      "| loss_policy         | 28.5     |\n",
      "| loss_q              | 887      |\n",
      "| mean_episode_length | 350      |\n",
      "| mean_episode_reward | -88.8    |\n",
      "| norm_grads          | 315      |\n",
      "| norm_grads_policy   | 78.2     |\n",
      "| norm_grads_q        | 305      |\n",
      "| total_timesteps     | 22020    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| avg_norm_adj        | 1.02     |\n",
      "| avg_norm_g          | 5.91     |\n",
      "| avg_norm_grads_f    | 5.32     |\n",
      "| avg_norm_k          | 2.09     |\n",
      "| avg_norm_k_dot_g    | 5.8      |\n",
      "| entropy             | 16.7     |\n",
      "| explained_variance  | -0.105   |\n",
      "| fps                 | 821      |\n",
      "| loss                | -0.262   |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -1.16    |\n",
      "| loss_policy         | -1.16    |\n",
      "| loss_q              | 2.12     |\n",
      "| mean_episode_length | 378      |\n",
      "| mean_episode_reward | -73.4    |\n",
      "| norm_grads          | 12.7     |\n",
      "| norm_grads_policy   | 3.59     |\n",
      "| norm_grads_q        | 12.1     |\n",
      "| total_timesteps     | 24020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.398    |\n",
      "| avg_norm_g          | 18.5     |\n",
      "| avg_norm_grads_f    | 18.2     |\n",
      "| avg_norm_k          | 1.75     |\n",
      "| avg_norm_k_dot_g    | 19.1     |\n",
      "| entropy             | 15.5     |\n",
      "| explained_variance  | 0.063    |\n",
      "| fps                 | 808      |\n",
      "| loss                | 45.5     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 4.89     |\n",
      "| loss_policy         | 4.89     |\n",
      "| loss_q              | 81.6     |\n",
      "| mean_episode_length | 414      |\n",
      "| mean_episode_reward | -59.9    |\n",
      "| norm_grads          | 45.9     |\n",
      "| norm_grads_policy   | 6.32     |\n",
      "| norm_grads_q        | 45.4     |\n",
      "| total_timesteps     | 26020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.0161   |\n",
      "| avg_norm_g          | 0.725    |\n",
      "| avg_norm_grads_f    | 0.712    |\n",
      "| avg_norm_k          | 1.98     |\n",
      "| avg_norm_k_dot_g    | 0.716    |\n",
      "| entropy             | 13.5     |\n",
      "| explained_variance  | -0.0151  |\n",
      "| fps                 | 801      |\n",
      "| loss                | -0.319   |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.224   |\n",
      "| loss_policy         | -0.224   |\n",
      "| loss_q              | 0.0812   |\n",
      "| mean_episode_length | 417      |\n",
      "| mean_episode_reward | -47.9    |\n",
      "| norm_grads          | 4.12     |\n",
      "| norm_grads_policy   | 0.323    |\n",
      "| norm_grads_q        | 4.11     |\n",
      "| total_timesteps     | 28020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.0122   |\n",
      "| avg_norm_g          | 5.4      |\n",
      "| avg_norm_grads_f    | 5.39     |\n",
      "| avg_norm_k          | 1.99     |\n",
      "| avg_norm_k_dot_g    | 5.02     |\n",
      "| entropy             | 10.8     |\n",
      "| explained_variance  | 0.907    |\n",
      "| fps                 | 809      |\n",
      "| loss                | 3.6      |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 1.56     |\n",
      "| loss_policy         | 1.56     |\n",
      "| loss_q              | 4.3      |\n",
      "| mean_episode_length | 404      |\n",
      "| mean_episode_reward | -48.8    |\n",
      "| norm_grads          | 21.6     |\n",
      "| norm_grads_policy   | 7.86     |\n",
      "| norm_grads_q        | 20.1     |\n",
      "| total_timesteps     | 30020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 43.5     |\n",
      "| avg_norm_grads_f    | 43.5     |\n",
      "| avg_norm_k          | 2.04     |\n",
      "| avg_norm_k_dot_g    | 40.6     |\n",
      "| entropy             | 9.17     |\n",
      "| explained_variance  | -2.12    |\n",
      "| fps                 | 818      |\n",
      "| loss                | 67.7     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 11       |\n",
      "| loss_policy         | 11       |\n",
      "| loss_q              | 114      |\n",
      "| mean_episode_length | 405      |\n",
      "| mean_episode_reward | -44.3    |\n",
      "| norm_grads          | 180      |\n",
      "| norm_grads_policy   | 69.2     |\n",
      "| norm_grads_q        | 166      |\n",
      "| total_timesteps     | 32020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.177    |\n",
      "| avg_norm_g          | 1.5      |\n",
      "| avg_norm_grads_f    | 1.37     |\n",
      "| avg_norm_k          | 1.92     |\n",
      "| avg_norm_k_dot_g    | 1.53     |\n",
      "| entropy             | 10.4     |\n",
      "| explained_variance  | 0.939    |\n",
      "| fps                 | 817      |\n",
      "| loss                | -0.0674  |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.228   |\n",
      "| loss_policy         | -0.228   |\n",
      "| loss_q              | 0.529    |\n",
      "| mean_episode_length | 422      |\n",
      "| mean_episode_reward | -15.6    |\n",
      "| norm_grads          | 7.05     |\n",
      "| norm_grads_policy   | 3.5      |\n",
      "| norm_grads_q        | 6.12     |\n",
      "| total_timesteps     | 34020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 3.35     |\n",
      "| avg_norm_g          | 17.1     |\n",
      "| avg_norm_grads_f    | 15       |\n",
      "| avg_norm_k          | 1.61     |\n",
      "| avg_norm_k_dot_g    | 15.1     |\n",
      "| entropy             | 7.7      |\n",
      "| explained_variance  | 0.227    |\n",
      "| fps                 | 817      |\n",
      "| loss                | 24.9     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.511   |\n",
      "| loss_policy         | -0.511   |\n",
      "| loss_q              | 50.9     |\n",
      "| mean_episode_length | 387      |\n",
      "| mean_episode_reward | 5.09     |\n",
      "| norm_grads          | 36.6     |\n",
      "| norm_grads_policy   | 23.1     |\n",
      "| norm_grads_q        | 28.3     |\n",
      "| total_timesteps     | 36020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.0481   |\n",
      "| avg_norm_g          | 3.23     |\n",
      "| avg_norm_grads_f    | 3.18     |\n",
      "| avg_norm_k          | 2.1      |\n",
      "| avg_norm_k_dot_g    | 2.76     |\n",
      "| entropy             | 13.5     |\n",
      "| explained_variance  | 0.663    |\n",
      "| fps                 | 810      |\n",
      "| loss                | 1.55     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.849    |\n",
      "| loss_policy         | 0.849    |\n",
      "| loss_q              | 1.68     |\n",
      "| mean_episode_length | 329      |\n",
      "| mean_episode_reward | 3.57     |\n",
      "| norm_grads          | 9.51     |\n",
      "| norm_grads_policy   | 8.24     |\n",
      "| norm_grads_q        | 4.75     |\n",
      "| total_timesteps     | 38020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 16.9     |\n",
      "| avg_norm_grads_f    | 16.9     |\n",
      "| avg_norm_k          | 1.94     |\n",
      "| avg_norm_k_dot_g    | 21.4     |\n",
      "| entropy             | 10.3     |\n",
      "| explained_variance  | 0.367    |\n",
      "| fps                 | 811      |\n",
      "| loss                | 12.4     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 4.21     |\n",
      "| loss_policy         | 4.21     |\n",
      "| loss_q              | 16.5     |\n",
      "| mean_episode_length | 272      |\n",
      "| mean_episode_reward | -1.09    |\n",
      "| norm_grads          | 30       |\n",
      "| norm_grads_policy   | 23.8     |\n",
      "| norm_grads_q        | 18.3     |\n",
      "| total_timesteps     | 40020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.0532   |\n",
      "| avg_norm_g          | 11.2     |\n",
      "| avg_norm_grads_f    | 11.1     |\n",
      "| avg_norm_k          | 2.52     |\n",
      "| avg_norm_k_dot_g    | 11.1     |\n",
      "| entropy             | 1.9      |\n",
      "| explained_variance  | -0.696   |\n",
      "| fps                 | 804      |\n",
      "| loss                | 50.5     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.11    |\n",
      "| loss_policy         | -0.11    |\n",
      "| loss_q              | 101      |\n",
      "| mean_episode_length | 282      |\n",
      "| mean_episode_reward | -8.24    |\n",
      "| norm_grads          | 143      |\n",
      "| norm_grads_policy   | 1.56     |\n",
      "| norm_grads_q        | 143      |\n",
      "| total_timesteps     | 42020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 66.9     |\n",
      "| avg_norm_grads_f    | 66.9     |\n",
      "| avg_norm_k          | 1.82     |\n",
      "| avg_norm_k_dot_g    | 73.9     |\n",
      "| entropy             | 4.57     |\n",
      "| explained_variance  | 0.505    |\n",
      "| fps                 | 803      |\n",
      "| loss                | 469      |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 10.9     |\n",
      "| loss_policy         | 10.9     |\n",
      "| loss_q              | 916      |\n",
      "| mean_episode_length | 293      |\n",
      "| mean_episode_reward | 7.89     |\n",
      "| norm_grads          | 506      |\n",
      "| norm_grads_policy   | 55.3     |\n",
      "| norm_grads_q        | 503      |\n",
      "| total_timesteps     | 44020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.379    |\n",
      "| avg_norm_g          | 13.9     |\n",
      "| avg_norm_grads_f    | 13.6     |\n",
      "| avg_norm_k          | 1.73     |\n",
      "| avg_norm_k_dot_g    | 13.1     |\n",
      "| entropy             | 8.22     |\n",
      "| explained_variance  | 0.695    |\n",
      "| fps                 | 799      |\n",
      "| loss                | 16.7     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 2.13     |\n",
      "| loss_policy         | 2.13     |\n",
      "| loss_q              | 29.3     |\n",
      "| mean_episode_length | 283      |\n",
      "| mean_episode_reward | 10.1     |\n",
      "| norm_grads          | 35.3     |\n",
      "| norm_grads_policy   | 1.53     |\n",
      "| norm_grads_q        | 35.2     |\n",
      "| total_timesteps     | 46020    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| avg_norm_adj        | 20.2     |\n",
      "| avg_norm_g          | 83.7     |\n",
      "| avg_norm_grads_f    | 73.8     |\n",
      "| avg_norm_k          | 1.96     |\n",
      "| avg_norm_k_dot_g    | 73.5     |\n",
      "| entropy             | 6.37     |\n",
      "| explained_variance  | -0.0997  |\n",
      "| fps                 | 799      |\n",
      "| loss                | 741      |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -7.36    |\n",
      "| loss_policy         | -7.36    |\n",
      "| loss_q              | 1.5e+03  |\n",
      "| mean_episode_length | 251      |\n",
      "| mean_episode_reward | -14.8    |\n",
      "| norm_grads          | 345      |\n",
      "| norm_grads_policy   | 48.4     |\n",
      "| norm_grads_q        | 341      |\n",
      "| total_timesteps     | 48020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 25.6     |\n",
      "| avg_norm_g          | 79.7     |\n",
      "| avg_norm_grads_f    | 64.7     |\n",
      "| avg_norm_k          | 1.81     |\n",
      "| avg_norm_k_dot_g    | 83.5     |\n",
      "| entropy             | 3.93     |\n",
      "| explained_variance  | -0.107   |\n",
      "| fps                 | 801      |\n",
      "| loss                | 1.26e+03 |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -16.2    |\n",
      "| loss_policy         | -16.2    |\n",
      "| loss_q              | 2.56e+03 |\n",
      "| mean_episode_length | 248      |\n",
      "| mean_episode_reward | -7.85    |\n",
      "| norm_grads          | 601      |\n",
      "| norm_grads_policy   | 60.6     |\n",
      "| norm_grads_q        | 598      |\n",
      "| total_timesteps     | 50020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.67     |\n",
      "| avg_norm_g          | 10.8     |\n",
      "| avg_norm_grads_f    | 10.4     |\n",
      "| avg_norm_k          | 2.28     |\n",
      "| avg_norm_k_dot_g    | 10.7     |\n",
      "| entropy             | 6.17     |\n",
      "| explained_variance  | -0.911   |\n",
      "| fps                 | 802      |\n",
      "| loss                | 10.2     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 1.51     |\n",
      "| loss_policy         | 1.51     |\n",
      "| loss_q              | 17.5     |\n",
      "| mean_episode_length | 225      |\n",
      "| mean_episode_reward | 8.47     |\n",
      "| norm_grads          | 32.2     |\n",
      "| norm_grads_policy   | 7.11     |\n",
      "| norm_grads_q        | 31.4     |\n",
      "| total_timesteps     | 52020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 16       |\n",
      "| avg_norm_g          | 63.1     |\n",
      "| avg_norm_grads_f    | 56.5     |\n",
      "| avg_norm_k          | 1.74     |\n",
      "| avg_norm_k_dot_g    | 49.3     |\n",
      "| entropy             | 0.583    |\n",
      "| explained_variance  | 0.0197   |\n",
      "| fps                 | 800      |\n",
      "| loss                | -0.0499  |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -1.06    |\n",
      "| loss_policy         | -1.06    |\n",
      "| loss_q              | 2.02     |\n",
      "| mean_episode_length | 231      |\n",
      "| mean_episode_reward | -10.5    |\n",
      "| norm_grads          | 40       |\n",
      "| norm_grads_policy   | 2.07     |\n",
      "| norm_grads_q        | 40       |\n",
      "| total_timesteps     | 54020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 1.29     |\n",
      "| avg_norm_g          | 5.54     |\n",
      "| avg_norm_grads_f    | 4.25     |\n",
      "| avg_norm_k          | 1.84     |\n",
      "| avg_norm_k_dot_g    | 5.45     |\n",
      "| entropy             | 18       |\n",
      "| explained_variance  | 0.135    |\n",
      "| fps                 | 795      |\n",
      "| loss                | 1.25     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -1.76    |\n",
      "| loss_policy         | -1.76    |\n",
      "| loss_q              | 6.37     |\n",
      "| mean_episode_length | 241      |\n",
      "| mean_episode_reward | -11.1    |\n",
      "| norm_grads          | 94.2     |\n",
      "| norm_grads_policy   | 1.98     |\n",
      "| norm_grads_q        | 94.2     |\n",
      "| total_timesteps     | 56020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 39.5     |\n",
      "| avg_norm_grads_f    | 39.5     |\n",
      "| avg_norm_k          | 1.69     |\n",
      "| avg_norm_k_dot_g    | 40.8     |\n",
      "| entropy             | 11.9     |\n",
      "| explained_variance  | -0.016   |\n",
      "| fps                 | 789      |\n",
      "| loss                | 97.4     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 11.5     |\n",
      "| loss_policy         | 11.5     |\n",
      "| loss_q              | 172      |\n",
      "| mean_episode_length | 280      |\n",
      "| mean_episode_reward | -9.64    |\n",
      "| norm_grads          | 51.1     |\n",
      "| norm_grads_policy   | 14.8     |\n",
      "| norm_grads_q        | 48.9     |\n",
      "| total_timesteps     | 58020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.152    |\n",
      "| avg_norm_g          | 12.1     |\n",
      "| avg_norm_grads_f    | 12       |\n",
      "| avg_norm_k          | 1.98     |\n",
      "| avg_norm_k_dot_g    | 11.1     |\n",
      "| entropy             | 12       |\n",
      "| explained_variance  | 0.592    |\n",
      "| fps                 | 791      |\n",
      "| loss                | 25.9     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 2.73     |\n",
      "| loss_policy         | 2.73     |\n",
      "| loss_q              | 46.5     |\n",
      "| mean_episode_length | 299      |\n",
      "| mean_episode_reward | 12.4     |\n",
      "| norm_grads          | 43.1     |\n",
      "| norm_grads_policy   | 14       |\n",
      "| norm_grads_q        | 40.7     |\n",
      "| total_timesteps     | 60020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 1.35     |\n",
      "| avg_norm_g          | 5.69     |\n",
      "| avg_norm_grads_f    | 4.79     |\n",
      "| avg_norm_k          | 1.73     |\n",
      "| avg_norm_k_dot_g    | 5.06     |\n",
      "| entropy             | 14.5     |\n",
      "| explained_variance  | -0.0872  |\n",
      "| fps                 | 786      |\n",
      "| loss                | 2.12     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -1.88    |\n",
      "| loss_policy         | -1.88    |\n",
      "| loss_q              | 8.3      |\n",
      "| mean_episode_length | 314      |\n",
      "| mean_episode_reward | 27.3     |\n",
      "| norm_grads          | 72.1     |\n",
      "| norm_grads_policy   | 9.78     |\n",
      "| norm_grads_q        | 71.4     |\n",
      "| total_timesteps     | 62020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.399    |\n",
      "| avg_norm_g          | 2.38     |\n",
      "| avg_norm_grads_f    | 2.09     |\n",
      "| avg_norm_k          | 2.04     |\n",
      "| avg_norm_k_dot_g    | 2.5      |\n",
      "| entropy             | 14.6     |\n",
      "| explained_variance  | 0.0801   |\n",
      "| fps                 | 788      |\n",
      "| loss                | -0.484   |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.826   |\n",
      "| loss_policy         | -0.826   |\n",
      "| loss_q              | 0.974    |\n",
      "| mean_episode_length | 332      |\n",
      "| mean_episode_reward | 32       |\n",
      "| norm_grads          | 28.3     |\n",
      "| norm_grads_policy   | 1.41     |\n",
      "| norm_grads_q        | 28.2     |\n",
      "| total_timesteps     | 64020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.00321  |\n",
      "| avg_norm_g          | 0.714    |\n",
      "| avg_norm_grads_f    | 0.711    |\n",
      "| avg_norm_k          | 1.84     |\n",
      "| avg_norm_k_dot_g    | 0.719    |\n",
      "| entropy             | 10.4     |\n",
      "| explained_variance  | 0.0976   |\n",
      "| fps                 | 789      |\n",
      "| loss                | 0.0608   |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.07     |\n",
      "| loss_policy         | 0.07     |\n",
      "| loss_q              | 0.189    |\n",
      "| mean_episode_length | 375      |\n",
      "| mean_episode_reward | 38.1     |\n",
      "| norm_grads          | 10.9     |\n",
      "| norm_grads_policy   | 1.41     |\n",
      "| norm_grads_q        | 10.8     |\n",
      "| total_timesteps     | 66020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 3.6      |\n",
      "| avg_norm_g          | 12.5     |\n",
      "| avg_norm_grads_f    | 10.4     |\n",
      "| avg_norm_k          | 1.76     |\n",
      "| avg_norm_k_dot_g    | 12.3     |\n",
      "| entropy             | 11.7     |\n",
      "| explained_variance  | 0.661    |\n",
      "| fps                 | 780      |\n",
      "| loss                | 14.1     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -3.25    |\n",
      "| loss_policy         | -3.25    |\n",
      "| loss_q              | 34.9     |\n",
      "| mean_episode_length | 416      |\n",
      "| mean_episode_reward | 50.7     |\n",
      "| norm_grads          | 119      |\n",
      "| norm_grads_policy   | 1.14     |\n",
      "| norm_grads_q        | 119      |\n",
      "| total_timesteps     | 68020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.836    |\n",
      "| avg_norm_g          | 4.22     |\n",
      "| avg_norm_grads_f    | 3.7      |\n",
      "| avg_norm_k          | 2        |\n",
      "| avg_norm_k_dot_g    | 4.27     |\n",
      "| entropy             | 10.1     |\n",
      "| explained_variance  | 0.235    |\n",
      "| fps                 | 778      |\n",
      "| loss                | -0.391   |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -1.07    |\n",
      "| loss_policy         | -1.07    |\n",
      "| loss_q              | 1.55     |\n",
      "| mean_episode_length | 406      |\n",
      "| mean_episode_reward | 71.4     |\n",
      "| norm_grads          | 39.7     |\n",
      "| norm_grads_policy   | 3.15     |\n",
      "| norm_grads_q        | 39.6     |\n",
      "| total_timesteps     | 70020    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| avg_norm_adj        | 1.16     |\n",
      "| avg_norm_g          | 5.64     |\n",
      "| avg_norm_grads_f    | 4.97     |\n",
      "| avg_norm_k          | 1.95     |\n",
      "| avg_norm_k_dot_g    | 5.45     |\n",
      "| entropy             | 16.3     |\n",
      "| explained_variance  | 0.367    |\n",
      "| fps                 | 772      |\n",
      "| loss                | 0.144    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -1.5     |\n",
      "| loss_policy         | -1.5     |\n",
      "| loss_q              | 3.62     |\n",
      "| mean_episode_length | 458      |\n",
      "| mean_episode_reward | 82       |\n",
      "| norm_grads          | 30.2     |\n",
      "| norm_grads_policy   | 7.49     |\n",
      "| norm_grads_q        | 29.2     |\n",
      "| total_timesteps     | 72020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 30.4     |\n",
      "| avg_norm_grads_f    | 30.4     |\n",
      "| avg_norm_k          | 1.82     |\n",
      "| avg_norm_k_dot_g    | 26.7     |\n",
      "| entropy             | 11.7     |\n",
      "| explained_variance  | -2       |\n",
      "| fps                 | 768      |\n",
      "| loss                | 89.1     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 8.69     |\n",
      "| loss_policy         | 8.69     |\n",
      "| loss_q              | 161      |\n",
      "| mean_episode_length | 489      |\n",
      "| mean_episode_reward | 86.9     |\n",
      "| norm_grads          | 343      |\n",
      "| norm_grads_policy   | 43.1     |\n",
      "| norm_grads_q        | 341      |\n",
      "| total_timesteps     | 74020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 3.82     |\n",
      "| avg_norm_grads_f    | 3.82     |\n",
      "| avg_norm_k          | 1.74     |\n",
      "| avg_norm_k_dot_g    | 3.94     |\n",
      "| entropy             | 13.2     |\n",
      "| explained_variance  | 0.942    |\n",
      "| fps                 | 770      |\n",
      "| loss                | 3.53     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 1.03     |\n",
      "| loss_policy         | 1.03     |\n",
      "| loss_q              | 5.26     |\n",
      "| mean_episode_length | 481      |\n",
      "| mean_episode_reward | 104      |\n",
      "| norm_grads          | 28.8     |\n",
      "| norm_grads_policy   | 6.54     |\n",
      "| norm_grads_q        | 28.1     |\n",
      "| total_timesteps     | 76020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 0.276    |\n",
      "| avg_norm_grads_f    | 0.276    |\n",
      "| avg_norm_k          | 1.55     |\n",
      "| avg_norm_k_dot_g    | 0.245    |\n",
      "| entropy             | 7.86     |\n",
      "| explained_variance  | 0.0162   |\n",
      "| fps                 | 767      |\n",
      "| loss                | -0.0398  |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.0247   |\n",
      "| loss_policy         | 0.0247   |\n",
      "| loss_q              | 0.0282   |\n",
      "| mean_episode_length | 483      |\n",
      "| mean_episode_reward | 112      |\n",
      "| norm_grads          | 3.07     |\n",
      "| norm_grads_policy   | 0.204    |\n",
      "| norm_grads_q        | 3.06     |\n",
      "| total_timesteps     | 78020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 1.22     |\n",
      "| avg_norm_g          | 5.42     |\n",
      "| avg_norm_grads_f    | 4.65     |\n",
      "| avg_norm_k          | 1.93     |\n",
      "| avg_norm_k_dot_g    | 5.41     |\n",
      "| entropy             | 22.3     |\n",
      "| explained_variance  | 0.904    |\n",
      "| fps                 | 763      |\n",
      "| loss                | -0.282   |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -1.7     |\n",
      "| loss_policy         | -1.7     |\n",
      "| loss_q              | 3.29     |\n",
      "| mean_episode_length | 519      |\n",
      "| mean_episode_reward | 127      |\n",
      "| norm_grads          | 45.1     |\n",
      "| norm_grads_policy   | 2.79     |\n",
      "| norm_grads_q        | 45       |\n",
      "| total_timesteps     | 80020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 13.1     |\n",
      "| avg_norm_grads_f    | 13.1     |\n",
      "| avg_norm_k          | 1.83     |\n",
      "| avg_norm_k_dot_g    | 13.2     |\n",
      "| entropy             | 11.7     |\n",
      "| explained_variance  | 0.685    |\n",
      "| fps                 | 760      |\n",
      "| loss                | 15.7     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 3.71     |\n",
      "| loss_policy         | 3.71     |\n",
      "| loss_q              | 24.2     |\n",
      "| mean_episode_length | 545      |\n",
      "| mean_episode_reward | 136      |\n",
      "| norm_grads          | 87.2     |\n",
      "| norm_grads_policy   | 32.2     |\n",
      "| norm_grads_q        | 81.1     |\n",
      "| total_timesteps     | 82020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.545    |\n",
      "| avg_norm_g          | 3.37     |\n",
      "| avg_norm_grads_f    | 3.01     |\n",
      "| avg_norm_k          | 2.17     |\n",
      "| avg_norm_k_dot_g    | 3.41     |\n",
      "| entropy             | 18.9     |\n",
      "| explained_variance  | 0.741    |\n",
      "| fps                 | 757      |\n",
      "| loss                | -0.324   |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.991   |\n",
      "| loss_policy         | -0.991   |\n",
      "| loss_q              | 1.71     |\n",
      "| mean_episode_length | 587      |\n",
      "| mean_episode_reward | 141      |\n",
      "| norm_grads          | 29.1     |\n",
      "| norm_grads_policy   | 4.8      |\n",
      "| norm_grads_q        | 28.7     |\n",
      "| total_timesteps     | 84020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 7.03     |\n",
      "| avg_norm_g          | 33.3     |\n",
      "| avg_norm_grads_f    | 29.9     |\n",
      "| avg_norm_k          | 2.03     |\n",
      "| avg_norm_k_dot_g    | 30.4     |\n",
      "| entropy             | 7.16     |\n",
      "| explained_variance  | -8.93    |\n",
      "| fps                 | 756      |\n",
      "| loss                | 17.1     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -4.62    |\n",
      "| loss_policy         | -4.62    |\n",
      "| loss_q              | 43.7     |\n",
      "| mean_episode_length | 582      |\n",
      "| mean_episode_reward | 151      |\n",
      "| norm_grads          | 61.6     |\n",
      "| norm_grads_policy   | 27.3     |\n",
      "| norm_grads_q        | 55.3     |\n",
      "| total_timesteps     | 86020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 16       |\n",
      "| avg_norm_grads_f    | 16       |\n",
      "| avg_norm_k          | 2        |\n",
      "| avg_norm_k_dot_g    | 17.8     |\n",
      "| entropy             | 17.5     |\n",
      "| explained_variance  | -0.159   |\n",
      "| fps                 | 749      |\n",
      "| loss                | 12.2     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 4.25     |\n",
      "| loss_policy         | 4.25     |\n",
      "| loss_q              | 16.3     |\n",
      "| mean_episode_length | 620      |\n",
      "| mean_episode_reward | 151      |\n",
      "| norm_grads          | 98.6     |\n",
      "| norm_grads_policy   | 19.8     |\n",
      "| norm_grads_q        | 96.6     |\n",
      "| total_timesteps     | 88020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.109    |\n",
      "| avg_norm_g          | 60.6     |\n",
      "| avg_norm_grads_f    | 60.6     |\n",
      "| avg_norm_k          | 1.98     |\n",
      "| avg_norm_k_dot_g    | 61.6     |\n",
      "| entropy             | 4.91     |\n",
      "| explained_variance  | -1.54    |\n",
      "| fps                 | 750      |\n",
      "| loss                | 9.45     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 2.78     |\n",
      "| loss_policy         | 2.78     |\n",
      "| loss_q              | 13.4     |\n",
      "| mean_episode_length | 601      |\n",
      "| mean_episode_reward | 155      |\n",
      "| norm_grads          | 96.8     |\n",
      "| norm_grads_policy   | 5.94     |\n",
      "| norm_grads_q        | 96.6     |\n",
      "| total_timesteps     | 90020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 9.33     |\n",
      "| avg_norm_g          | 33.8     |\n",
      "| avg_norm_grads_f    | 28.6     |\n",
      "| avg_norm_k          | 1.91     |\n",
      "| avg_norm_k_dot_g    | 33.8     |\n",
      "| entropy             | 6.37     |\n",
      "| explained_variance  | 0.511    |\n",
      "| fps                 | 751      |\n",
      "| loss                | 746      |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.435   |\n",
      "| loss_policy         | -0.435   |\n",
      "| loss_q              | 1.49e+03 |\n",
      "| mean_episode_length | 569      |\n",
      "| mean_episode_reward | 149      |\n",
      "| norm_grads          | 740      |\n",
      "| norm_grads_policy   | 13.4     |\n",
      "| norm_grads_q        | 740      |\n",
      "| total_timesteps     | 92020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 0.186    |\n",
      "| avg_norm_grads_f    | 0.186    |\n",
      "| avg_norm_k          | 2.04     |\n",
      "| avg_norm_k_dot_g    | 0.186    |\n",
      "| entropy             | 3.53     |\n",
      "| explained_variance  | -0.0261  |\n",
      "| fps                 | 751      |\n",
      "| loss                | -0.0289  |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.00611 |\n",
      "| loss_policy         | -0.00611 |\n",
      "| loss_q              | 0.0251   |\n",
      "| mean_episode_length | 569      |\n",
      "| mean_episode_reward | 148      |\n",
      "| norm_grads          | 4.41     |\n",
      "| norm_grads_policy   | 0.0649   |\n",
      "| norm_grads_q        | 4.41     |\n",
      "| total_timesteps     | 94020    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| avg_norm_adj        | 14.8     |\n",
      "| avg_norm_g          | 45.7     |\n",
      "| avg_norm_grads_f    | 37.4     |\n",
      "| avg_norm_k          | 1.69     |\n",
      "| avg_norm_k_dot_g    | 45.7     |\n",
      "| entropy             | 0.529    |\n",
      "| explained_variance  | 0.193    |\n",
      "| fps                 | 749      |\n",
      "| loss                | 1.05e+03 |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.0753  |\n",
      "| loss_policy         | -0.0753  |\n",
      "| loss_q              | 2.11e+03 |\n",
      "| mean_episode_length | 524      |\n",
      "| mean_episode_reward | 148      |\n",
      "| norm_grads          | 876      |\n",
      "| norm_grads_policy   | 1.04     |\n",
      "| norm_grads_q        | 876      |\n",
      "| total_timesteps     | 96020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 59.9     |\n",
      "| avg_norm_grads_f    | 59.9     |\n",
      "| avg_norm_k          | 1.69     |\n",
      "| avg_norm_k_dot_g    | 59.9     |\n",
      "| entropy             | 2.31     |\n",
      "| explained_variance  | 0.182    |\n",
      "| fps                 | 747      |\n",
      "| loss                | 1.27e+03 |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 2.34     |\n",
      "| loss_policy         | 2.34     |\n",
      "| loss_q              | 2.53e+03 |\n",
      "| mean_episode_length | 541      |\n",
      "| mean_episode_reward | 150      |\n",
      "| norm_grads          | 1.15e+03 |\n",
      "| norm_grads_policy   | 19.3     |\n",
      "| norm_grads_q        | 1.15e+03 |\n",
      "| total_timesteps     | 98020    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines.acer.acer_simple.ACER at 0x7f8a2084b0f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explained_variance: as higher as possible\n",
    "mean_episode_length = \n",
    "mean_episode_reward: as higher as possible\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Save and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"ACER_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ACER.load(\"ACER_model\", env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()  ## back to basic state\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, done, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
